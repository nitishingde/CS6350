{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 15:21:17.240931: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-19 15:21:17.455264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:17.455309: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-19 15:21:18.537737: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:18.537886: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:18.537903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       age         workclass  fnlwgt  education.num      marital.status  \\\n0       53  Self-emp-not-inc   93449             15  Married-civ-spouse   \n1       33  Self-emp-not-inc  123424             13  Married-civ-spouse   \n2       47           Private  144844              9  Married-civ-spouse   \n3       40           Private  114580              9            Divorced   \n4       39           Private  115618              9  Married-civ-spouse   \n...    ...               ...     ...            ...                 ...   \n24995   18           Private   83451              9       Never-married   \n24996   64         Local-gov  202738              9  Married-civ-spouse   \n24997   39           Private  225544             14  Married-civ-spouse   \n24998   53           Private  346871              9            Divorced   \n24999   18           Private  192321             10       Never-married   \n\n             occupation    relationship                race     sex  \\\n0        Prof-specialty         Husband  Asian-Pac-Islander    Male   \n1       Exec-managerial         Husband               White    Male   \n2          Craft-repair         Husband               White    Male   \n3          Craft-repair  Other-relative               White  Female   \n4      Transport-moving         Husband               White    Male   \n...                 ...             ...                 ...     ...   \n24995      Adm-clerical   Not-in-family               White  Female   \n24996      Adm-clerical            Wife               White  Female   \n24997  Transport-moving         Husband               White    Male   \n24998    Prof-specialty   Not-in-family               White    Male   \n24999    Prof-specialty       Own-child               White    Male   \n\n       capital.gain  capital.loss  hours.per.week native.country  income>50K  \n0                 0             0              40          India           1  \n1                 0             0              40  United-States           1  \n2                 0             0              40  United-States           0  \n3                 0             0              40        Vietnam           0  \n4                 0             0              50  United-States           0  \n...             ...           ...             ...            ...         ...  \n24995             0             0              25  United-States           0  \n24996             0             0              35  United-States           0  \n24997             0             0              40         Poland           0  \n24998          4787             0              46  United-States           1  \n24999             0             0              40  United-States           0  \n\n[25000 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education.num</th>\n      <th>marital.status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital.gain</th>\n      <th>capital.loss</th>\n      <th>hours.per.week</th>\n      <th>native.country</th>\n      <th>income&gt;50K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>53</td>\n      <td>Self-emp-not-inc</td>\n      <td>93449</td>\n      <td>15</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Husband</td>\n      <td>Asian-Pac-Islander</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>India</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33</td>\n      <td>Self-emp-not-inc</td>\n      <td>123424</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>Private</td>\n      <td>144844</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Craft-repair</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40</td>\n      <td>Private</td>\n      <td>114580</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Craft-repair</td>\n      <td>Other-relative</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Vietnam</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39</td>\n      <td>Private</td>\n      <td>115618</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Transport-moving</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>18</td>\n      <td>Private</td>\n      <td>83451</td>\n      <td>9</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>64</td>\n      <td>Local-gov</td>\n      <td>202738</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Adm-clerical</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>35</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>39</td>\n      <td>Private</td>\n      <td>225544</td>\n      <td>14</td>\n      <td>Married-civ-spouse</td>\n      <td>Transport-moving</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Poland</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>346871</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Prof-specialty</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>4787</td>\n      <td>0</td>\n      <td>46</td>\n      <td>United-States</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>18</td>\n      <td>Private</td>\n      <td>192321</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>Prof-specialty</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train_final.csv')\n",
    "df_train.drop(['education'], axis=1, inplace=True)\n",
    "workclass_maxf = df_train['workclass'].value_counts().index[0]\n",
    "occupation_maxf = df_train['occupation'].value_counts().index[0]\n",
    "native_country_maxf = df_train['native.country'].value_counts().index[0]\n",
    "df_train = df_train.replace('?', np.nan)\n",
    "df_train['workclass'].fillna(workclass_maxf, inplace=True)\n",
    "df_train['occupation'].fillna(occupation_maxf, inplace=True)\n",
    "df_train['native.country'].fillna(native_country_maxf, inplace=True)\n",
    "df_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       age         workclass  fnlwgt  education.num      marital.status  \\\n0       33  Self-emp-not-inc  222162              9  Married-civ-spouse   \n1       68           Private   29240              9             Widowed   \n2       34           Private  103596              9  Married-civ-spouse   \n3       57           Private  103403              3  Married-civ-spouse   \n4       48           Private  152915             10       Never-married   \n...    ...               ...     ...            ...                 ...   \n23837   26           Private   43408             13  Married-civ-spouse   \n23838   27           Private  116372             13       Never-married   \n23839   67      Self-emp-inc  182581             10  Married-civ-spouse   \n23840   46         Local-gov  274689             12            Divorced   \n23841   66       Federal-gov   47358              6  Married-civ-spouse   \n\n              occupation   relationship   race     sex  capital.gain  \\\n0           Craft-repair        Husband  White    Male             0   \n1         Prof-specialty  Not-in-family  White  Female             0   \n2      Handlers-cleaners        Husband  White    Male             0   \n3       Transport-moving        Husband  White    Male             0   \n4           Adm-clerical  Not-in-family  White  Female             0   \n...                  ...            ...    ...     ...           ...   \n23837     Prof-specialty        Husband  White    Male             0   \n23838     Prof-specialty  Not-in-family  White  Female             0   \n23839    Exec-managerial        Husband  White    Male         20051   \n23840    Protective-serv  Not-in-family  White    Male             0   \n23841       Craft-repair        Husband  White    Male          3471   \n\n       capital.loss  hours.per.week native.country  \n0                 0              40  United-States  \n1                 0              12  United-States  \n2                 0              40  United-States  \n3                 0              40  United-States  \n4                 0              40  United-States  \n...             ...             ...            ...  \n23837             0              40  United-States  \n23838             0              40  United-States  \n23839             0              20  United-States  \n23840             0              40  United-States  \n23841             0              40  United-States  \n\n[23842 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education.num</th>\n      <th>marital.status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital.gain</th>\n      <th>capital.loss</th>\n      <th>hours.per.week</th>\n      <th>native.country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33</td>\n      <td>Self-emp-not-inc</td>\n      <td>222162</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Craft-repair</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>68</td>\n      <td>Private</td>\n      <td>29240</td>\n      <td>9</td>\n      <td>Widowed</td>\n      <td>Prof-specialty</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34</td>\n      <td>Private</td>\n      <td>103596</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>57</td>\n      <td>Private</td>\n      <td>103403</td>\n      <td>3</td>\n      <td>Married-civ-spouse</td>\n      <td>Transport-moving</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>48</td>\n      <td>Private</td>\n      <td>152915</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23837</th>\n      <td>26</td>\n      <td>Private</td>\n      <td>43408</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>23838</th>\n      <td>27</td>\n      <td>Private</td>\n      <td>116372</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Prof-specialty</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>23839</th>\n      <td>67</td>\n      <td>Self-emp-inc</td>\n      <td>182581</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>20051</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>23840</th>\n      <td>46</td>\n      <td>Local-gov</td>\n      <td>274689</td>\n      <td>12</td>\n      <td>Divorced</td>\n      <td>Protective-serv</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>23841</th>\n      <td>66</td>\n      <td>Federal-gov</td>\n      <td>47358</td>\n      <td>6</td>\n      <td>Married-civ-spouse</td>\n      <td>Craft-repair</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>3471</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n  </tbody>\n</table>\n<p>23842 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./data/test_final.csv')\n",
    "df_test.drop(['ID', 'education'], axis=1, inplace=True)\n",
    "df_test = df_test.replace('?', np.nan)\n",
    "df_test['workclass'].fillna(workclass_maxf, inplace=True)\n",
    "df_test['occupation'].fillna(occupation_maxf, inplace=True)\n",
    "df_test['native.country'].fillna(native_country_maxf, inplace=True)\n",
    "df_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_703515/3948410678.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  x_combn = x_train.append(df_test)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = df_train.iloc[:, :-1], df_train.iloc[:, -1]\n",
    "x_combn = x_train.append(df_test)\n",
    "x_combn = pd.get_dummies(x_combn)\n",
    "for col in ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']:\n",
    "    x_combn[col] = x_combn[col]/x_combn[col].max()\n",
    "x_train, x_test = x_combn.iloc[:len(y_train),:], x_combn.iloc[len(y_train):,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "            age    fnlwgt  education.num  capital.gain  capital.loss  \\\n0      0.588889  0.062701         0.9375       0.00000           0.0   \n1      0.366667  0.082813         0.8125       0.00000           0.0   \n2      0.522222  0.097185         0.5625       0.00000           0.0   \n3      0.444444  0.076879         0.5625       0.00000           0.0   \n4      0.433333  0.077575         0.5625       0.00000           0.0   \n...         ...       ...            ...           ...           ...   \n24995  0.200000  0.055992         0.5625       0.00000           0.0   \n24996  0.711111  0.136029         0.5625       0.00000           0.0   \n24997  0.433333  0.151331         0.8750       0.00000           0.0   \n24998  0.588889  0.232737         0.5625       0.04787           0.0   \n24999  0.200000  0.129040         0.6250       0.00000           0.0   \n\n       hours.per.week  workclass_Federal-gov  workclass_Local-gov  \\\n0            0.404040                      0                    0   \n1            0.404040                      0                    0   \n2            0.404040                      0                    0   \n3            0.404040                      0                    0   \n4            0.505051                      0                    0   \n...               ...                    ...                  ...   \n24995        0.252525                      0                    0   \n24996        0.353535                      0                    1   \n24997        0.404040                      0                    0   \n24998        0.464646                      0                    0   \n24999        0.404040                      0                    0   \n\n       workclass_Never-worked  workclass_Private  ...  \\\n0                           0                  0  ...   \n1                           0                  0  ...   \n2                           0                  1  ...   \n3                           0                  1  ...   \n4                           0                  1  ...   \n...                       ...                ...  ...   \n24995                       0                  1  ...   \n24996                       0                  0  ...   \n24997                       0                  1  ...   \n24998                       0                  1  ...   \n24999                       0                  1  ...   \n\n       native.country_Portugal  native.country_Puerto-Rico  \\\n0                            0                           0   \n1                            0                           0   \n2                            0                           0   \n3                            0                           0   \n4                            0                           0   \n...                        ...                         ...   \n24995                        0                           0   \n24996                        0                           0   \n24997                        0                           0   \n24998                        0                           0   \n24999                        0                           0   \n\n       native.country_Scotland  native.country_South  native.country_Taiwan  \\\n0                            0                     0                      0   \n1                            0                     0                      0   \n2                            0                     0                      0   \n3                            0                     0                      0   \n4                            0                     0                      0   \n...                        ...                   ...                    ...   \n24995                        0                     0                      0   \n24996                        0                     0                      0   \n24997                        0                     0                      0   \n24998                        0                     0                      0   \n24999                        0                     0                      0   \n\n       native.country_Thailand  native.country_Trinadad&Tobago  \\\n0                            0                               0   \n1                            0                               0   \n2                            0                               0   \n3                            0                               0   \n4                            0                               0   \n...                        ...                             ...   \n24995                        0                               0   \n24996                        0                               0   \n24997                        0                               0   \n24998                        0                               0   \n24999                        0                               0   \n\n       native.country_United-States  native.country_Vietnam  \\\n0                                 0                       0   \n1                                 1                       0   \n2                                 1                       0   \n3                                 0                       1   \n4                                 1                       0   \n...                             ...                     ...   \n24995                             1                       0   \n24996                             1                       0   \n24997                             0                       0   \n24998                             1                       0   \n24999                             1                       0   \n\n       native.country_Yugoslavia  \n0                              0  \n1                              0  \n2                              0  \n3                              0  \n4                              0  \n...                          ...  \n24995                          0  \n24996                          0  \n24997                          0  \n24998                          0  \n24999                          0  \n\n[25000 rows x 89 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>fnlwgt</th>\n      <th>education.num</th>\n      <th>capital.gain</th>\n      <th>capital.loss</th>\n      <th>hours.per.week</th>\n      <th>workclass_Federal-gov</th>\n      <th>workclass_Local-gov</th>\n      <th>workclass_Never-worked</th>\n      <th>workclass_Private</th>\n      <th>...</th>\n      <th>native.country_Portugal</th>\n      <th>native.country_Puerto-Rico</th>\n      <th>native.country_Scotland</th>\n      <th>native.country_South</th>\n      <th>native.country_Taiwan</th>\n      <th>native.country_Thailand</th>\n      <th>native.country_Trinadad&amp;Tobago</th>\n      <th>native.country_United-States</th>\n      <th>native.country_Vietnam</th>\n      <th>native.country_Yugoslavia</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.588889</td>\n      <td>0.062701</td>\n      <td>0.9375</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.366667</td>\n      <td>0.082813</td>\n      <td>0.8125</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.522222</td>\n      <td>0.097185</td>\n      <td>0.5625</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.444444</td>\n      <td>0.076879</td>\n      <td>0.5625</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.433333</td>\n      <td>0.077575</td>\n      <td>0.5625</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.505051</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>0.200000</td>\n      <td>0.055992</td>\n      <td>0.5625</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.252525</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>0.711111</td>\n      <td>0.136029</td>\n      <td>0.5625</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.353535</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>0.433333</td>\n      <td>0.151331</td>\n      <td>0.8750</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>0.588889</td>\n      <td>0.232737</td>\n      <td>0.5625</td>\n      <td>0.04787</td>\n      <td>0.0</td>\n      <td>0.464646</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>0.200000</td>\n      <td>0.129040</td>\n      <td>0.6250</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows Ã— 89 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "            age    fnlwgt  education.num  capital.gain  capital.loss  \\\n0      0.366667  0.149062         0.5625      0.000000           0.0   \n1      0.755556  0.019619         0.5625      0.000000           0.0   \n2      0.377778  0.069509         0.5625      0.000000           0.0   \n3      0.633333  0.069379         0.1875      0.000000           0.0   \n4      0.533333  0.102600         0.6250      0.000000           0.0   \n...         ...       ...            ...           ...           ...   \n23837  0.288889  0.029125         0.8125      0.000000           0.0   \n23838  0.300000  0.078081         0.8125      0.000000           0.0   \n23839  0.744444  0.122505         0.6250      0.200512           0.0   \n23840  0.511111  0.184306         0.7500      0.000000           0.0   \n23841  0.733333  0.031775         0.3750      0.034710           0.0   \n\n       hours.per.week  workclass_Federal-gov  workclass_Local-gov  \\\n0            0.404040                      0                    0   \n1            0.121212                      0                    0   \n2            0.404040                      0                    0   \n3            0.404040                      0                    0   \n4            0.404040                      0                    0   \n...               ...                    ...                  ...   \n23837        0.404040                      0                    0   \n23838        0.404040                      0                    0   \n23839        0.202020                      0                    0   \n23840        0.404040                      0                    1   \n23841        0.404040                      1                    0   \n\n       workclass_Never-worked  workclass_Private  ...  \\\n0                           0                  0  ...   \n1                           0                  1  ...   \n2                           0                  1  ...   \n3                           0                  1  ...   \n4                           0                  1  ...   \n...                       ...                ...  ...   \n23837                       0                  1  ...   \n23838                       0                  1  ...   \n23839                       0                  0  ...   \n23840                       0                  0  ...   \n23841                       0                  0  ...   \n\n       native.country_Portugal  native.country_Puerto-Rico  \\\n0                            0                           0   \n1                            0                           0   \n2                            0                           0   \n3                            0                           0   \n4                            0                           0   \n...                        ...                         ...   \n23837                        0                           0   \n23838                        0                           0   \n23839                        0                           0   \n23840                        0                           0   \n23841                        0                           0   \n\n       native.country_Scotland  native.country_South  native.country_Taiwan  \\\n0                            0                     0                      0   \n1                            0                     0                      0   \n2                            0                     0                      0   \n3                            0                     0                      0   \n4                            0                     0                      0   \n...                        ...                   ...                    ...   \n23837                        0                     0                      0   \n23838                        0                     0                      0   \n23839                        0                     0                      0   \n23840                        0                     0                      0   \n23841                        0                     0                      0   \n\n       native.country_Thailand  native.country_Trinadad&Tobago  \\\n0                            0                               0   \n1                            0                               0   \n2                            0                               0   \n3                            0                               0   \n4                            0                               0   \n...                        ...                             ...   \n23837                        0                               0   \n23838                        0                               0   \n23839                        0                               0   \n23840                        0                               0   \n23841                        0                               0   \n\n       native.country_United-States  native.country_Vietnam  \\\n0                                 1                       0   \n1                                 1                       0   \n2                                 1                       0   \n3                                 1                       0   \n4                                 1                       0   \n...                             ...                     ...   \n23837                             1                       0   \n23838                             1                       0   \n23839                             1                       0   \n23840                             1                       0   \n23841                             1                       0   \n\n       native.country_Yugoslavia  \n0                              0  \n1                              0  \n2                              0  \n3                              0  \n4                              0  \n...                          ...  \n23837                          0  \n23838                          0  \n23839                          0  \n23840                          0  \n23841                          0  \n\n[23842 rows x 89 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>fnlwgt</th>\n      <th>education.num</th>\n      <th>capital.gain</th>\n      <th>capital.loss</th>\n      <th>hours.per.week</th>\n      <th>workclass_Federal-gov</th>\n      <th>workclass_Local-gov</th>\n      <th>workclass_Never-worked</th>\n      <th>workclass_Private</th>\n      <th>...</th>\n      <th>native.country_Portugal</th>\n      <th>native.country_Puerto-Rico</th>\n      <th>native.country_Scotland</th>\n      <th>native.country_South</th>\n      <th>native.country_Taiwan</th>\n      <th>native.country_Thailand</th>\n      <th>native.country_Trinadad&amp;Tobago</th>\n      <th>native.country_United-States</th>\n      <th>native.country_Vietnam</th>\n      <th>native.country_Yugoslavia</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.366667</td>\n      <td>0.149062</td>\n      <td>0.5625</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.755556</td>\n      <td>0.019619</td>\n      <td>0.5625</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.121212</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.377778</td>\n      <td>0.069509</td>\n      <td>0.5625</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.633333</td>\n      <td>0.069379</td>\n      <td>0.1875</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.533333</td>\n      <td>0.102600</td>\n      <td>0.6250</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23837</th>\n      <td>0.288889</td>\n      <td>0.029125</td>\n      <td>0.8125</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23838</th>\n      <td>0.300000</td>\n      <td>0.078081</td>\n      <td>0.8125</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23839</th>\n      <td>0.744444</td>\n      <td>0.122505</td>\n      <td>0.6250</td>\n      <td>0.200512</td>\n      <td>0.0</td>\n      <td>0.202020</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23840</th>\n      <td>0.511111</td>\n      <td>0.184306</td>\n      <td>0.7500</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23841</th>\n      <td>0.733333</td>\n      <td>0.031775</td>\n      <td>0.3750</td>\n      <td>0.034710</td>\n      <td>0.0</td>\n      <td>0.404040</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23842 rows Ã— 89 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "x = x_train\n",
    "y = y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 15:21:20.131536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-19 15:21:20.132053: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:20.132282: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:20.132420: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:20.132510: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:20.132583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:20.132676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:20.132772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:20.132856: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-19 15:21:20.132878: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-19 15:21:20.133802: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "391/391 [==============================] - 6s 12ms/step - loss: 0.3932 - accuracy: 0.8144\n",
      "Epoch 2/256\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.3406 - accuracy: 0.8408\n",
      "Epoch 3/256\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.3329 - accuracy: 0.8430\n",
      "Epoch 4/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.3223 - accuracy: 0.8473\n",
      "Epoch 5/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.3166 - accuracy: 0.8529\n",
      "Epoch 6/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.3129 - accuracy: 0.8546\n",
      "Epoch 7/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.3097 - accuracy: 0.8567\n",
      "Epoch 8/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.3041 - accuracy: 0.8583\n",
      "Epoch 9/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.3004 - accuracy: 0.8600\n",
      "Epoch 10/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2966 - accuracy: 0.8617\n",
      "Epoch 11/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2936 - accuracy: 0.8624\n",
      "Epoch 12/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2902 - accuracy: 0.8643\n",
      "Epoch 13/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2872 - accuracy: 0.8651\n",
      "Epoch 14/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2838 - accuracy: 0.8683\n",
      "Epoch 15/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2797 - accuracy: 0.8694\n",
      "Epoch 16/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2776 - accuracy: 0.8684\n",
      "Epoch 17/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2731 - accuracy: 0.8713\n",
      "Epoch 18/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2717 - accuracy: 0.8740\n",
      "Epoch 19/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2695 - accuracy: 0.8746\n",
      "Epoch 20/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2673 - accuracy: 0.8746\n",
      "Epoch 21/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2655 - accuracy: 0.8756\n",
      "Epoch 22/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2647 - accuracy: 0.8750\n",
      "Epoch 23/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2606 - accuracy: 0.8764\n",
      "Epoch 24/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2590 - accuracy: 0.8770\n",
      "Epoch 25/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2578 - accuracy: 0.8762\n",
      "Epoch 26/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2565 - accuracy: 0.8772\n",
      "Epoch 27/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2553 - accuracy: 0.8771\n",
      "Epoch 28/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2523 - accuracy: 0.8781\n",
      "Epoch 29/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2516 - accuracy: 0.8791\n",
      "Epoch 30/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2494 - accuracy: 0.8803\n",
      "Epoch 31/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2467 - accuracy: 0.8820\n",
      "Epoch 32/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2464 - accuracy: 0.8812\n",
      "Epoch 33/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2447 - accuracy: 0.8818\n",
      "Epoch 34/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2467 - accuracy: 0.8812\n",
      "Epoch 35/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2429 - accuracy: 0.8822\n",
      "Epoch 36/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2420 - accuracy: 0.8841\n",
      "Epoch 37/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2402 - accuracy: 0.8850\n",
      "Epoch 38/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2381 - accuracy: 0.8851\n",
      "Epoch 39/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2385 - accuracy: 0.8842\n",
      "Epoch 40/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2382 - accuracy: 0.8868\n",
      "Epoch 41/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2354 - accuracy: 0.8868\n",
      "Epoch 42/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2332 - accuracy: 0.8872\n",
      "Epoch 43/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2323 - accuracy: 0.8886\n",
      "Epoch 44/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2307 - accuracy: 0.8880\n",
      "Epoch 45/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2301 - accuracy: 0.8888\n",
      "Epoch 46/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2300 - accuracy: 0.8881\n",
      "Epoch 47/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2283 - accuracy: 0.8899\n",
      "Epoch 48/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2270 - accuracy: 0.8907\n",
      "Epoch 49/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2270 - accuracy: 0.8891\n",
      "Epoch 50/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2231 - accuracy: 0.8919\n",
      "Epoch 51/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2226 - accuracy: 0.8928\n",
      "Epoch 52/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2199 - accuracy: 0.8915\n",
      "Epoch 53/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2214 - accuracy: 0.8925\n",
      "Epoch 54/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2179 - accuracy: 0.8943\n",
      "Epoch 55/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2183 - accuracy: 0.8946\n",
      "Epoch 56/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2152 - accuracy: 0.8958\n",
      "Epoch 57/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2160 - accuracy: 0.8968\n",
      "Epoch 58/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2127 - accuracy: 0.8969\n",
      "Epoch 59/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2135 - accuracy: 0.8968\n",
      "Epoch 60/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2116 - accuracy: 0.8960\n",
      "Epoch 61/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2107 - accuracy: 0.8982\n",
      "Epoch 62/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2094 - accuracy: 0.8997\n",
      "Epoch 63/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2105 - accuracy: 0.8980\n",
      "Epoch 64/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2063 - accuracy: 0.9000\n",
      "Epoch 65/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2063 - accuracy: 0.8998\n",
      "Epoch 66/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2023 - accuracy: 0.9029\n",
      "Epoch 67/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2016 - accuracy: 0.9035\n",
      "Epoch 68/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1995 - accuracy: 0.9038\n",
      "Epoch 69/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1991 - accuracy: 0.9038\n",
      "Epoch 70/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1985 - accuracy: 0.9054\n",
      "Epoch 71/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1978 - accuracy: 0.9034\n",
      "Epoch 72/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1986 - accuracy: 0.9035\n",
      "Epoch 73/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1961 - accuracy: 0.9052\n",
      "Epoch 74/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1936 - accuracy: 0.9072\n",
      "Epoch 75/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1921 - accuracy: 0.9083\n",
      "Epoch 76/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1938 - accuracy: 0.9062\n",
      "Epoch 77/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1915 - accuracy: 0.9064\n",
      "Epoch 78/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1922 - accuracy: 0.9077\n",
      "Epoch 79/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1868 - accuracy: 0.9092\n",
      "Epoch 80/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1863 - accuracy: 0.9084\n",
      "Epoch 81/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1905 - accuracy: 0.9088\n",
      "Epoch 82/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1921 - accuracy: 0.9081\n",
      "Epoch 83/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1840 - accuracy: 0.9104\n",
      "Epoch 84/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1856 - accuracy: 0.9106\n",
      "Epoch 85/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1782 - accuracy: 0.9140\n",
      "Epoch 86/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1770 - accuracy: 0.9138\n",
      "Epoch 87/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1760 - accuracy: 0.9141\n",
      "Epoch 88/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1764 - accuracy: 0.9142\n",
      "Epoch 89/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1784 - accuracy: 0.9141\n",
      "Epoch 90/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1768 - accuracy: 0.9153\n",
      "Epoch 91/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1728 - accuracy: 0.9150\n",
      "Epoch 92/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1721 - accuracy: 0.9164\n",
      "Epoch 93/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1721 - accuracy: 0.9157\n",
      "Epoch 94/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1763 - accuracy: 0.9159\n",
      "Epoch 95/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1736 - accuracy: 0.9180\n",
      "Epoch 96/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1679 - accuracy: 0.9194\n",
      "Epoch 97/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1687 - accuracy: 0.9184\n",
      "Epoch 98/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1694 - accuracy: 0.9198\n",
      "Epoch 99/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1664 - accuracy: 0.9201\n",
      "Epoch 100/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1630 - accuracy: 0.9212\n",
      "Epoch 101/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1666 - accuracy: 0.9202\n",
      "Epoch 102/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1625 - accuracy: 0.9211\n",
      "Epoch 103/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1615 - accuracy: 0.9225\n",
      "Epoch 104/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1619 - accuracy: 0.9229\n",
      "Epoch 105/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1637 - accuracy: 0.9213\n",
      "Epoch 106/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1628 - accuracy: 0.9225\n",
      "Epoch 107/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1612 - accuracy: 0.9217\n",
      "Epoch 108/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1548 - accuracy: 0.9252\n",
      "Epoch 109/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1530 - accuracy: 0.9248\n",
      "Epoch 110/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1552 - accuracy: 0.9254\n",
      "Epoch 111/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1512 - accuracy: 0.9274\n",
      "Epoch 112/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1618 - accuracy: 0.9227\n",
      "Epoch 113/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1544 - accuracy: 0.9266\n",
      "Epoch 114/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1517 - accuracy: 0.9280\n",
      "Epoch 115/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1580 - accuracy: 0.9252\n",
      "Epoch 116/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1672 - accuracy: 0.9238\n",
      "Epoch 117/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1508 - accuracy: 0.9286\n",
      "Epoch 118/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1475 - accuracy: 0.9306\n",
      "Epoch 119/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1404 - accuracy: 0.9324\n",
      "Epoch 120/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1418 - accuracy: 0.9315\n",
      "Epoch 121/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1417 - accuracy: 0.9322\n",
      "Epoch 122/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1443 - accuracy: 0.9313\n",
      "Epoch 123/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1476 - accuracy: 0.9294\n",
      "Epoch 124/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1434 - accuracy: 0.9322\n",
      "Epoch 125/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1484 - accuracy: 0.9284\n",
      "Epoch 126/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1483 - accuracy: 0.9301\n",
      "Epoch 127/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1387 - accuracy: 0.9343\n",
      "Epoch 128/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1341 - accuracy: 0.9344\n",
      "Epoch 129/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1346 - accuracy: 0.9347\n",
      "Epoch 130/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1387 - accuracy: 0.9338\n",
      "Epoch 131/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1418 - accuracy: 0.9338\n",
      "Epoch 132/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1354 - accuracy: 0.9347\n",
      "Epoch 133/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1383 - accuracy: 0.9344\n",
      "Epoch 134/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1318 - accuracy: 0.9374\n",
      "Epoch 135/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1341 - accuracy: 0.9356\n",
      "Epoch 136/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1356 - accuracy: 0.9364\n",
      "Epoch 137/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1319 - accuracy: 0.9368\n",
      "Epoch 138/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1296 - accuracy: 0.9372\n",
      "Epoch 139/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1305 - accuracy: 0.9382\n",
      "Epoch 140/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1259 - accuracy: 0.9400\n",
      "Epoch 141/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1303 - accuracy: 0.9384\n",
      "Epoch 142/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1264 - accuracy: 0.9402\n",
      "Epoch 143/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1348 - accuracy: 0.9374\n",
      "Epoch 144/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1354 - accuracy: 0.9371\n",
      "Epoch 145/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1334 - accuracy: 0.9377\n",
      "Epoch 146/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1462 - accuracy: 0.9326\n",
      "Epoch 147/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1331 - accuracy: 0.9388\n",
      "Epoch 148/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1268 - accuracy: 0.9431\n",
      "Epoch 149/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1286 - accuracy: 0.9414\n",
      "Epoch 150/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1199 - accuracy: 0.9445\n",
      "Epoch 151/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1144 - accuracy: 0.9454\n",
      "Epoch 152/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1268 - accuracy: 0.9406\n",
      "Epoch 153/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1163 - accuracy: 0.9456\n",
      "Epoch 154/256\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.1122 - accuracy: 0.9466\n",
      "Epoch 155/256\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.1169 - accuracy: 0.9448\n",
      "Epoch 156/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1179 - accuracy: 0.9441\n",
      "Epoch 157/256\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1249 - accuracy: 0.9419\n",
      "Epoch 158/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1244 - accuracy: 0.9422\n",
      "Epoch 159/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1255 - accuracy: 0.9430\n",
      "Epoch 160/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1137 - accuracy: 0.9463\n",
      "Epoch 161/256\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1134 - accuracy: 0.9467\n",
      "Epoch 162/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1114 - accuracy: 0.9477\n",
      "Epoch 163/256\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1122 - accuracy: 0.9468\n",
      "Epoch 164/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1133 - accuracy: 0.9465\n",
      "Epoch 165/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1123 - accuracy: 0.9464\n",
      "Epoch 166/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1204 - accuracy: 0.9450\n",
      "Epoch 167/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1210 - accuracy: 0.9437\n",
      "Epoch 168/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1096 - accuracy: 0.9484\n",
      "Epoch 169/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1141 - accuracy: 0.9484\n",
      "Epoch 170/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1121 - accuracy: 0.9476\n",
      "Epoch 171/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1192 - accuracy: 0.9458\n",
      "Epoch 172/256\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1065 - accuracy: 0.9503\n",
      "Epoch 173/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1050 - accuracy: 0.9505\n",
      "Epoch 174/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1037 - accuracy: 0.9516\n",
      "Epoch 175/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1053 - accuracy: 0.9505\n",
      "Epoch 176/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1024 - accuracy: 0.9522\n",
      "Epoch 177/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1041 - accuracy: 0.9514\n",
      "Epoch 178/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1122 - accuracy: 0.9482\n",
      "Epoch 179/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1283 - accuracy: 0.9434\n",
      "Epoch 180/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1051 - accuracy: 0.9519\n",
      "Epoch 181/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0978 - accuracy: 0.9548\n",
      "Epoch 182/256\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0980 - accuracy: 0.9539\n",
      "Epoch 183/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0979 - accuracy: 0.9545\n",
      "Epoch 184/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1042 - accuracy: 0.9514\n",
      "Epoch 185/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1003 - accuracy: 0.9523\n",
      "Epoch 186/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0971 - accuracy: 0.9538\n",
      "Epoch 187/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0993 - accuracy: 0.9550\n",
      "Epoch 188/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1005 - accuracy: 0.9539\n",
      "Epoch 189/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1011 - accuracy: 0.9529\n",
      "Epoch 190/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1053 - accuracy: 0.9530\n",
      "Epoch 191/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0989 - accuracy: 0.9545\n",
      "Epoch 192/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1008 - accuracy: 0.9522\n",
      "Epoch 193/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0942 - accuracy: 0.9573\n",
      "Epoch 194/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0954 - accuracy: 0.9558\n",
      "Epoch 195/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0991 - accuracy: 0.9538\n",
      "Epoch 196/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1166 - accuracy: 0.9496\n",
      "Epoch 197/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1026 - accuracy: 0.9542\n",
      "Epoch 198/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0915 - accuracy: 0.9588\n",
      "Epoch 199/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0884 - accuracy: 0.9589\n",
      "Epoch 200/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0902 - accuracy: 0.9579\n",
      "Epoch 201/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0900 - accuracy: 0.9583\n",
      "Epoch 202/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0979 - accuracy: 0.9562\n",
      "Epoch 203/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1050 - accuracy: 0.9522\n",
      "Epoch 204/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1001 - accuracy: 0.9564\n",
      "Epoch 205/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0888 - accuracy: 0.9595\n",
      "Epoch 206/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0916 - accuracy: 0.9582\n",
      "Epoch 207/256\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0929 - accuracy: 0.9574\n",
      "Epoch 208/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0969 - accuracy: 0.9554\n",
      "Epoch 209/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0908 - accuracy: 0.9585\n",
      "Epoch 210/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0917 - accuracy: 0.9594\n",
      "Epoch 211/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0893 - accuracy: 0.9590\n",
      "Epoch 212/256\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0935 - accuracy: 0.9581\n",
      "Epoch 213/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0866 - accuracy: 0.9589\n",
      "Epoch 214/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0896 - accuracy: 0.9594\n",
      "Epoch 215/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0835 - accuracy: 0.9620\n",
      "Epoch 216/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0927 - accuracy: 0.9576\n",
      "Epoch 217/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1000 - accuracy: 0.9561\n",
      "Epoch 218/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0877 - accuracy: 0.9603\n",
      "Epoch 219/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0809 - accuracy: 0.9620\n",
      "Epoch 220/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0834 - accuracy: 0.9616\n",
      "Epoch 221/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0840 - accuracy: 0.9615\n",
      "Epoch 222/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0886 - accuracy: 0.9597\n",
      "Epoch 223/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0969 - accuracy: 0.9578\n",
      "Epoch 224/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0910 - accuracy: 0.9590\n",
      "Epoch 225/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0846 - accuracy: 0.9630\n",
      "Epoch 226/256\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0840 - accuracy: 0.9611\n",
      "Epoch 227/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0808 - accuracy: 0.9633\n",
      "Epoch 228/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0782 - accuracy: 0.9640\n",
      "Epoch 229/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0828 - accuracy: 0.9629\n",
      "Epoch 230/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0829 - accuracy: 0.9619\n",
      "Epoch 231/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0809 - accuracy: 0.9622\n",
      "Epoch 232/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0858 - accuracy: 0.9628\n",
      "Epoch 233/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0875 - accuracy: 0.9610\n",
      "Epoch 234/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0837 - accuracy: 0.9624\n",
      "Epoch 235/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0798 - accuracy: 0.9643\n",
      "Epoch 236/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0816 - accuracy: 0.9632\n",
      "Epoch 237/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0798 - accuracy: 0.9640\n",
      "Epoch 238/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0800 - accuracy: 0.9637\n",
      "Epoch 239/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0893 - accuracy: 0.9596\n",
      "Epoch 240/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0841 - accuracy: 0.9630\n",
      "Epoch 241/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0827 - accuracy: 0.9629\n",
      "Epoch 242/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0756 - accuracy: 0.9659\n",
      "Epoch 243/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0709 - accuracy: 0.9678\n",
      "Epoch 244/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0746 - accuracy: 0.9670\n",
      "Epoch 245/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0767 - accuracy: 0.9655\n",
      "Epoch 246/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0758 - accuracy: 0.9661\n",
      "Epoch 247/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0805 - accuracy: 0.9637\n",
      "Epoch 248/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0804 - accuracy: 0.9625\n",
      "Epoch 249/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0735 - accuracy: 0.9657\n",
      "Epoch 250/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0818 - accuracy: 0.9641\n",
      "Epoch 251/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1139 - accuracy: 0.9537\n",
      "Epoch 252/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0751 - accuracy: 0.9674\n",
      "Epoch 253/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0681 - accuracy: 0.9687\n",
      "Epoch 254/256\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0679 - accuracy: 0.9696\n",
      "Epoch 255/256\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0763 - accuracy: 0.9660\n",
      "Epoch 256/256\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0753 - accuracy: 0.9655\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fc87c0a7b80>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(x.columns.size*5, activation=keras.activations.relu, kernel_initializer=keras.initializers.glorot_uniform(), input_shape=(x.columns.size,)))\n",
    "model.add(Dense(x.columns.size*5, activation=keras.activations.relu, kernel_initializer=keras.initializers.glorot_uniform()))\n",
    "model.add(Dense(x.columns.size*5, activation=keras.activations.relu, kernel_initializer=keras.initializers.glorot_uniform()))\n",
    "model.add(Dense(x.columns.size*5, activation=keras.activations.relu, kernel_initializer=keras.initializers.glorot_uniform()))\n",
    "model.add(Dense(x.columns.size*5, activation=keras.activations.relu, kernel_initializer=keras.initializers.glorot_uniform()))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=256, batch_size=64, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_4\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_5\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2022-12-19 15:36:07      3363980\n",
      "metadata.json                                  2022-12-19 15:36:07           64\n",
      "config.json                                    2022-12-19 15:36:07         3574\n"
     ]
    }
   ],
   "source": [
    "with open('./nn_model1', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ans = pd.DataFrame.from_dict({\n",
    "    'ID': np.arange(1, len(x_test) + 1),\n",
    "    'Prediction': np.round(model.predict(x_test)).astype(int, copy=False)[:,0],\n",
    "})\n",
    "ans.to_csv('nn1.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_703515/4239105513.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  plt.matshow(df_train.corr())\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fc83a3f1160>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 480x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(df_train.corr())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def get_accuracy(my_model, input: pd.DataFrame, ans: pd.Series):\n",
    "    return 100.*sum(np.round(my_model.predict(input)).astype(int, copy=False)[:,0] == ans)/len(ans)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "97.116"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, x, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
